{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR images using Docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facial recognition using MTCNN ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mikae\\source\\repos\\image-file-namer\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from itertools import permutations\n",
    "\n",
    "class NameMatcher:\n",
    "    def __init__(self, names_file_path):\n",
    "        \"\"\"Initialize with a file containing list of valid names.\"\"\"\n",
    "        print(f\"Loading names from {names_file_path}...\")\n",
    "        self.first_names = set()\n",
    "        self.last_names = set()\n",
    "        self.full_names = set()\n",
    "        \n",
    "        try:\n",
    "            with open(names_file_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if not line or line.startswith('#'):\n",
    "                        continue\n",
    "                    \n",
    "                    # Check if the line specifies the name type\n",
    "                    if ':' in line:\n",
    "                        name_type, name = line.split(':', 1)\n",
    "                        name = name.strip().lower()\n",
    "                        if name_type.strip().lower() == 'first':\n",
    "                            self.first_names.add(name)\n",
    "                        elif name_type.strip().lower() == 'last':\n",
    "                            self.last_names.add(name)\n",
    "                        elif name_type.strip().lower() == 'full':\n",
    "                            self.full_names.add(name)\n",
    "                    else:\n",
    "                        # If no type specified, add to all sets\n",
    "                        name = line.lower()\n",
    "                        if ' ' in name:\n",
    "                            self.full_names.add(name)\n",
    "                        else:\n",
    "                            self.first_names.add(name)\n",
    "                            self.last_names.add(name)\n",
    "            \n",
    "            print(f\"Loaded {len(self.first_names)} first names\")\n",
    "            print(f\"Loaded {len(self.last_names)} last names\")\n",
    "            print(f\"Loaded {len(self.full_names)} full names\")\n",
    "            \n",
    "            # Create pattern for full names (including permutations)\n",
    "            self._create_patterns()\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Names file not found: {names_file_path}\")\n",
    "    \n",
    "    def _create_patterns(self):\n",
    "        \"\"\"Create regex patterns for different name formats.\"\"\"\n",
    "        # Pattern for full names (exact matches)\n",
    "        full_names_pattern = '|'.join(map(re.escape, sorted(self.full_names, key=len, reverse=True)))\n",
    "        \n",
    "        # Pattern for first+last name combinations\n",
    "        first_names_pattern = '|'.join(map(re.escape, sorted(self.first_names, key=len, reverse=True)))\n",
    "        last_names_pattern = '|'.join(map(re.escape, sorted(self.last_names, key=len, reverse=True)))\n",
    "        \n",
    "        # Combine patterns with optional middle names/initials\n",
    "        self.patterns = [\n",
    "            # Full names as-is\n",
    "            re.compile(full_names_pattern, re.IGNORECASE) if full_names_pattern else None,\n",
    "            \n",
    "            # First + Last name combinations\n",
    "            re.compile(f\"({first_names_pattern})[^a-zA-Z]*({last_names_pattern})\", re.IGNORECASE),\n",
    "            \n",
    "            # Last + First name combinations\n",
    "            re.compile(f\"({last_names_pattern})[^a-zA-Z]*({first_names_pattern})\", re.IGNORECASE),\n",
    "            \n",
    "            # Single first names\n",
    "            re.compile(f\"({first_names_pattern})\", re.IGNORECASE),\n",
    "            \n",
    "            # Single last names\n",
    "            re.compile(f\"({last_names_pattern})\", re.IGNORECASE)\n",
    "        ]\n",
    "        \n",
    "        self.patterns = [p for p in self.patterns if p is not None]\n",
    "    \n",
    "    def find_name(self, filename):\n",
    "        \"\"\"Find any matching names in the filename.\"\"\"\n",
    "        # Remove extension and clean filename\n",
    "        base_name = re.sub(r'\\.[^.]+$', '', filename)\n",
    "        base_name = re.sub(r'[_-]', ' ', base_name)  # Convert underscores/hyphens to spaces\n",
    "        \n",
    "        best_match = None\n",
    "        best_match_length = 0\n",
    "        \n",
    "        # Try each pattern in order of preference\n",
    "        for pattern in self.patterns:\n",
    "            matches = pattern.finditer(base_name.lower())\n",
    "            for match in matches:\n",
    "                # For patterns with groups, combine the groups\n",
    "                if len(match.groups()) > 1:\n",
    "                    name_parts = [g for g in match.groups() if g]\n",
    "                    matched_name = ' '.join(name_parts)\n",
    "                else:\n",
    "                    matched_name = match.group(0)\n",
    "                \n",
    "                # Keep the longest match\n",
    "                if len(matched_name) > best_match_length:\n",
    "                    best_match = matched_name\n",
    "                    best_match_length = len(matched_name)\n",
    "        \n",
    "        if best_match:\n",
    "            return True, best_match\n",
    "        return False, None\n",
    "\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, image_dir, names_file_path):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.name_matcher = NameMatcher(names_file_path)\n",
    "        \n",
    "        # Initialize face detection model\n",
    "        self.mtcnn = MTCNN(\n",
    "            image_size=160,\n",
    "            margin=10,\n",
    "            keep_all=True,\n",
    "            min_face_size=20,\n",
    "            device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        )\n",
    "        \n",
    "        # Filter images and extract labels\n",
    "        print(\"Scanning and filtering images...\")\n",
    "        skipped_no_name = 0\n",
    "        skipped_multiple_faces = 0\n",
    "        found_names = {}\n",
    "        \n",
    "        for filename in tqdm(os.listdir(image_dir)):\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):\n",
    "                image_path = os.path.join(image_dir, filename)\n",
    "                \n",
    "                # Extract name from filename\n",
    "                has_name, extracted_name = self.name_matcher.find_name(filename)\n",
    "                \n",
    "                if not has_name:\n",
    "                    skipped_no_name += 1\n",
    "                    if skipped_no_name <= 5:\n",
    "                        print(f\"Skipping {filename}: No known name found\")\n",
    "                    continue\n",
    "                \n",
    "                # Check number of faces\n",
    "                if not self._has_single_face(image_path):\n",
    "                    skipped_multiple_faces += 1\n",
    "                    if skipped_multiple_faces <= 5:\n",
    "                        print(f\"Skipping {filename}: Multiple faces detected or no face found\")\n",
    "                    continue\n",
    "                \n",
    "                self.image_paths.append(image_path)\n",
    "                self.labels.append(extracted_name)\n",
    "                found_names[extracted_name] = found_names.get(extracted_name, 0) + 1\n",
    "        \n",
    "        self._print_summary(found_names, skipped_no_name, skipped_multiple_faces)\n",
    "        \n",
    "        # Convert names to numerical labels\n",
    "        unique_names = list(found_names.keys())\n",
    "        self.name_to_idx = {name: idx for idx, name in enumerate(unique_names)}\n",
    "        self.labels = [self.name_to_idx[name] for name in self.labels]\n",
    "        \n",
    "        # Reinitialize MTCNN for single face detection\n",
    "        self.mtcnn = MTCNN(\n",
    "            image_size=160,\n",
    "            margin=10,\n",
    "            keep_all=False,\n",
    "            min_face_size=20,\n",
    "            device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        )\n",
    "\n",
    "    def _print_summary(self, found_names, skipped_no_name, skipped_multiple_faces):\n",
    "        print(f\"\\nDataset Summary:\")\n",
    "        print(f\"Found {len(self.image_paths)} valid images with single faces and valid names\")\n",
    "        print(f\"Skipped {skipped_no_name} images with no matching names\")\n",
    "        print(f\"Skipped {skipped_multiple_faces} images with multiple faces or no faces\")\n",
    "        print(f\"Unique names found: {len(found_names)}\")\n",
    "        \n",
    "        if found_names:\n",
    "            print(\"\\nMost common names found:\")\n",
    "            for name, count in sorted(found_names.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "                print(f\"  {name}: {count} images\")\n",
    "\n",
    "    def _has_single_face(self, image_path):\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "            boxes, _ = self.mtcnn.detect(image)\n",
    "            return boxes is not None and len(boxes) == 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx])\n",
    "        try:\n",
    "            face = self.mtcnn(image)\n",
    "            if face is None:\n",
    "                return torch.zeros((3, 160, 160)), self.labels[idx]\n",
    "            return face, self.labels[idx]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {self.image_paths[idx]}: {str(e)}\")\n",
    "            return torch.zeros((3, 160, 160)), self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(image_dir, names_file_path, batch_size=32, num_epochs=10, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Train the facial recognition model.\n",
    "    \n",
    "    Args:\n",
    "        image_dir (str): Directory containing face images\n",
    "        names_file_path (str): Path to the file containing valid names\n",
    "        batch_size (int): Batch size for training\n",
    "        num_epochs (int): Number of training epochs\n",
    "        learning_rate (float): Learning rate for optimization\n",
    "    \n",
    "    Returns:\n",
    "        model: Trained model\n",
    "        dataset: The dataset object for reference\n",
    "    \"\"\"\n",
    "    # Initialize dataset\n",
    "    dataset = FaceDataset(image_dir, names_file_path)\n",
    "    if len(dataset) == 0:\n",
    "        raise ValueError(\"No valid images found in the dataset\")\n",
    "    \n",
    "    # Create data loader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    model = InceptionResnetV1(pretrained='vggface2')\n",
    "    num_classes = len(dataset.name_to_idx)\n",
    "    # Replace the last layer to match our number of classes\n",
    "    model.last_linear = torch.nn.Linear(512, num_classes)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        print(\"Using GPU for training\")\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    print(f\"\\nStarting training with {num_epochs} epochs...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for i, (faces, labels) in enumerate(progress_bar):\n",
    "            if torch.cuda.is_available():\n",
    "                faces = faces.cuda()\n",
    "                labels = labels.cuda()\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(faces)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{running_loss/(i+1):.3f}',\n",
    "                'acc': f'{100*correct/total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # Epoch summary\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1} - Loss: {epoch_loss:.3f}, Accuracy: {epoch_acc:.2f}%')\n",
    "    \n",
    "    print(\"Training completed!\")\n",
    "    return model, dataset\n",
    "\n",
    "def save_model(model, save_path):\n",
    "    \"\"\"Save the trained model.\"\"\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "def load_model(model_path, num_classes):\n",
    "    \"\"\"Load a trained model.\"\"\"\n",
    "    model = InceptionResnetV1(pretrained=None)\n",
    "    model.last_linear = torch.nn.Linear(512, num_classes)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Training\n",
    "    model, dataset = train_model(\n",
    "        image_dir=\"C:/Users/Mikae/Documents/MEGA/Nedladdade frÃ¥n webb etc/1\",\n",
    "        names_file_path=\"path/to/names.txt\",\n",
    "        batch_size=32,\n",
    "        num_epochs=10\n",
    "    )\n",
    "    \n",
    "    # Save the model\n",
    "    save_model(model, \"facial_recognition_model.pth\")\n",
    "    \n",
    "    # Later, to load the model\n",
    "    loaded_model = load_model(\"facial_recognition_model.pth\", len(dataset.name_to_idx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
